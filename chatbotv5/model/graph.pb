node {
  name: "Variable/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "Variable"
  op: "VariableV2"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "Variable/Assign"
  op: "Assign"
  input: "Variable"
  input: "Variable/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@Variable"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "Variable/read"
  op: "Identity"
  input: "Variable"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@Variable"
      }
    }
  }
}
node {
  name: "mul/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.899999976158
      }
    }
  }
}
node {
  name: "mul"
  op: "Mul"
  input: "Variable/read"
  input: "mul/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "Assign"
  op: "Assign"
  input: "Variable"
  input: "mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@Variable"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "encoder0"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "encoder1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "encoder2"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "encoder3"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "encoder4"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "decoder0"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "decoder1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "decoder2"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "decoder3"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "decoder4"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "decoder5"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "weight0"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "weight1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "weight2"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "weight3"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "weight4"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/Shape"
  op: "Shape"
  input: "encoder0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/strided_slice"
  op: "StridedSlice"
  input: "embedding_attention_seq2seq/rnn/Shape"
  input: "embedding_attention_seq2seq/rnn/strided_slice/stack"
  input: "embedding_attention_seq2seq/rnn/strided_slice/stack_1"
  input: "embedding_attention_seq2seq/rnn/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims"
  op: "ExpandDims"
  input: "embedding_attention_seq2seq/rnn/strided_slice"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/Const"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros"
  op: "Fill"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_1/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_1"
  op: "ExpandDims"
  input: "embedding_attention_seq2seq/rnn/strided_slice"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_1/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2"
  op: "ExpandDims"
  input: "embedding_attention_seq2seq/rnn/strided_slice"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/Const_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat_1"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_2"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/Const_2"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat_1/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros_1"
  op: "Fill"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/concat_1"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros_1/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_3/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_3"
  op: "ExpandDims"
  input: "embedding_attention_seq2seq/rnn/strided_slice"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/ExpandDims_3/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/Const_3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -1.73205077648
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.73205077648
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
  op: "VariableV2"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 90
        }
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Initializer/random_uniform"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape/shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape"
  op: "Reshape"
  input: "encoder0"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape/shape"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup"
  op: "Gather"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape"
  device: "/device:CPU:0"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000 \000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.353553384542
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.353553384542
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
  op: "VariableV2"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 32
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 32
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Initializer/zeros"
  op: "Fill"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Initializer/zeros/shape_as_tensor"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
  op: "VariableV2"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 32
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Initializer/zeros"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat/axis"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat/axis"
  device: "/device:CPU:0"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_1"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split"
  op: "Split"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_2"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split:2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_2"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split:1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split:3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_1/shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_1"
  op: "Reshape"
  input: "encoder1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_1/shape"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1"
  op: "Gather"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_1"
  device: "/device:CPU:0"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_3"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1/axis"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1/axis"
  device: "/device:CPU:0"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_4"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1"
  op: "Split"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_5"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1:2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_5"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1:1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1:3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_2/shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_2"
  op: "Reshape"
  input: "encoder2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_2/shape"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2"
  op: "Gather"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_2"
  device: "/device:CPU:0"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_6"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2/axis"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2/axis"
  device: "/device:CPU:0"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_7"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2"
  op: "Split"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_6"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_8"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2:2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_8"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2:1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2:3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_3/shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_3"
  op: "Reshape"
  input: "encoder3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_3/shape"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3"
  op: "Gather"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_3"
  device: "/device:CPU:0"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_9"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3/axis"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3/axis"
  device: "/device:CPU:0"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_10"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3"
  op: "Split"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_9"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_11"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3:2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_11"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3:1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3:3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_4/shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_4"
  op: "Reshape"
  input: "encoder4"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_4/shape"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4"
  op: "Gather"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_4"
  device: "/device:CPU:0"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_12"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4/axis"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4/axis"
  device: "/device:CPU:0"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_13"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4"
  op: "Split"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_12"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_14"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4:2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_14"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4:1"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9"
  op: "Add"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9"
  op: "Tanh"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4:3"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2"
  input: "embedding_attention_seq2seq/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5"
  input: "embedding_attention_seq2seq/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_2"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8"
  input: "embedding_attention_seq2seq/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_3/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_3"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11"
  input: "embedding_attention_seq2seq/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_4/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 3
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/Reshape_4"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14"
  input: "embedding_attention_seq2seq/Reshape_4/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/Reshape"
  input: "embedding_attention_seq2seq/Reshape_1"
  input: "embedding_attention_seq2seq/Reshape_2"
  input: "embedding_attention_seq2seq/Reshape_3"
  input: "embedding_attention_seq2seq/Reshape_4"
  input: "embedding_attention_seq2seq/concat/axis"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.247435823083
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.247435823083
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 90
        }
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup"
  op: "Gather"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/read"
  input: "decoder0"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1"
  op: "Gather"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/read"
  input: "decoder1"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2"
  op: "Gather"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/read"
  input: "decoder2"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3"
  op: "Gather"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/read"
  input: "decoder3"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4"
  op: "Gather"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding/read"
  input: "decoder4"
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tparams"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "validate_indices"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice"
  op: "StridedSlice"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice/stack"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice/stack_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\005\000\000\000\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\001\000\000\000\001\000\000\000\010\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.612372457981
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.612372457981
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 1
        }
        dim {
          size: 1
        }
        dim {
          size: 8
        }
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  op: "Conv2D"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.612372457981
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.612372457981
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/stack/1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/stack"
  op: "Pack"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/strided_slice"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/stack/1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "axis"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros"
  op: "Fill"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/stack"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.5
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000 \000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.353553384542
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.353553384542
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 32
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Initializer/zeros/shape_as_tensor"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 32
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Initializer/zeros/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Initializer/zeros"
  op: "Fill"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Initializer/zeros/shape_as_tensor"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Initializer/zeros/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 32
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Initializer/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split"
  op: "Split"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split:2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split:3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\010\000\000\000Z\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.247435823083
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.247435823083
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 90
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 90
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 90
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\020\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.5
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.5
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 16
        }
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\002\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax"
  op: "Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\005\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\001\000\000\000\002\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "b\000\000\000Z\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.178647398949
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.178647398949
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 0
    }
  }
  attr {
    key: "seed2"
    value {
      i: 0
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/sub"
  op: "Sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/max"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/RandomUniform"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 98
        }
        dim {
          size: 90
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 90
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
  op: "VariableV2"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 90
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/Assign"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/read"
  op: "Identity"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Const"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_4"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1"
  op: "Split"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_5"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1:2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1:3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\002\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax"
  op: "Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\005\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\001\000\000\000\002\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/Const"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_6"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_7"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2"
  op: "Split"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_6"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_8"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2:2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2:3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\002\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax"
  op: "Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\005\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\001\000\000\000\002\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/Const"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_3"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_9"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_10"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3"
  op: "Split"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_11"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3:2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3:3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\002\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax"
  op: "Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\005\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\001\000\000\000\002\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/Const"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_4"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_4"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_12"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_13"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4"
  op: "Split"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_12"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "num_split"
    value {
      i: 4
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_14"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4:2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14"
  op: "Sigmoid"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4:3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000\001\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh"
  op: "Tanh"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\002\000\000\000\003\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax"
  op: "Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\377\377\377\377\005\000\000\000\001\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\001\000\000\000\002\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1"
  op: "Sum"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\010\000\000\000"
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2"
  op: "Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat"
  op: "ConcatV2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/Const"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd"
  op: "BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape"
  op: "Reshape"
  input: "decoder1"
  input: "sequence_loss/sequence_loss_by_example/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/Reshape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  op: "SparseSoftmaxCrossEntropyWithLogits"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd"
  input: "sequence_loss/sequence_loss_by_example/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tlabels"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/mul"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  input: "weight0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_1/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_1"
  op: "Reshape"
  input: "decoder2"
  input: "sequence_loss/sequence_loss_by_example/Reshape_1/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"
  op: "SparseSoftmaxCrossEntropyWithLogits"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd"
  input: "sequence_loss/sequence_loss_by_example/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tlabels"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/mul_1"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"
  input: "weight1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_2/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_2"
  op: "Reshape"
  input: "decoder3"
  input: "sequence_loss/sequence_loss_by_example/Reshape_2/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/Reshape_2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits"
  op: "SparseSoftmaxCrossEntropyWithLogits"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd"
  input: "sequence_loss/sequence_loss_by_example/Reshape_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tlabels"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/mul_2"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits"
  input: "weight2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_3/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_3"
  op: "Reshape"
  input: "decoder4"
  input: "sequence_loss/sequence_loss_by_example/Reshape_3/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits"
  op: "SparseSoftmaxCrossEntropyWithLogits"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd"
  input: "sequence_loss/sequence_loss_by_example/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tlabels"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/mul_3"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits"
  input: "weight3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_4/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/Reshape_4"
  op: "Reshape"
  input: "decoder5"
  input: "sequence_loss/sequence_loss_by_example/Reshape_4/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/Reshape_4"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits"
  op: "SparseSoftmaxCrossEntropyWithLogits"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd"
  input: "sequence_loss/sequence_loss_by_example/Reshape_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tlabels"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/mul_4"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits"
  input: "weight4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/AddN"
  op: "AddN"
  input: "sequence_loss/sequence_loss_by_example/mul"
  input: "sequence_loss/sequence_loss_by_example/mul_1"
  input: "sequence_loss/sequence_loss_by_example/mul_2"
  input: "sequence_loss/sequence_loss_by_example/mul_3"
  input: "sequence_loss/sequence_loss_by_example/mul_4"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/AddN_1"
  op: "AddN"
  input: "weight0"
  input: "weight1"
  input: "weight2"
  input: "weight3"
  input: "weight4"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/add/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.99999996004e-13
      }
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/add"
  op: "Add"
  input: "sequence_loss/sequence_loss_by_example/AddN_1"
  input: "sequence_loss/sequence_loss_by_example/add/y"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/sequence_loss_by_example/truediv"
  op: "RealDiv"
  input: "sequence_loss/sequence_loss_by_example/AddN"
  input: "sequence_loss/sequence_loss_by_example/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "sequence_loss/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "sequence_loss/Sum"
  op: "Sum"
  input: "sequence_loss/sequence_loss_by_example/truediv"
  input: "sequence_loss/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "sequence_loss/Shape"
  op: "Shape"
  input: "decoder1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "sequence_loss/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "sequence_loss/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "sequence_loss/strided_slice"
  op: "StridedSlice"
  input: "sequence_loss/Shape"
  input: "sequence_loss/strided_slice/stack"
  input: "sequence_loss/strided_slice/stack_1"
  input: "sequence_loss/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 1
    }
  }
}
node {
  name: "sequence_loss/Cast"
  op: "Cast"
  input: "sequence_loss/strided_slice"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "sequence_loss/truediv"
  op: "RealDiv"
  input: "sequence_loss/Sum"
  input: "sequence_loss/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/grad_ys_0"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "gradients/Fill"
  op: "Fill"
  input: "gradients/Shape"
  input: "gradients/grad_ys_0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/truediv_grad/Shape"
  input: "gradients/sequence_loss/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/Fill"
  input: "sequence_loss/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/truediv_grad/RealDiv"
  input: "gradients/sequence_loss/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/truediv_grad/Sum"
  input: "gradients/sequence_loss/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Neg"
  op: "Neg"
  input: "sequence_loss/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/sequence_loss/truediv_grad/Neg"
  input: "sequence_loss/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/sequence_loss/truediv_grad/RealDiv_1"
  input: "sequence_loss/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/mul"
  op: "Mul"
  input: "gradients/Fill"
  input: "gradients/sequence_loss/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/truediv_grad/mul"
  input: "gradients/sequence_loss/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/truediv_grad/Sum_1"
  input: "gradients/sequence_loss/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/truediv_grad/Reshape"
  input: "^gradients/sequence_loss/truediv_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/truediv_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/truediv_grad/Reshape"
  input: "^gradients/sequence_loss/truediv_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/truediv_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/truediv_grad/Reshape_1"
  input: "^gradients/sequence_loss/truediv_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/truediv_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/Sum_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/truediv_grad/tuple/control_dependency"
  input: "gradients/sequence_loss/Sum_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/Sum_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/sequence_loss/Sum_grad/Reshape"
  input: "gradients/sequence_loss/Sum_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/AddN"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Shape_1"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Shape"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/RealDiv"
  op: "RealDiv"
  input: "gradients/sequence_loss/Sum_grad/Tile"
  input: "sequence_loss/sequence_loss_by_example/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/RealDiv"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Neg"
  op: "Neg"
  input: "sequence_loss/sequence_loss_by_example/AddN"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/RealDiv_1"
  op: "RealDiv"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Neg"
  input: "sequence_loss/sequence_loss_by_example/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/RealDiv_2"
  op: "RealDiv"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/RealDiv_1"
  input: "sequence_loss/sequence_loss_by_example/add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/Sum_grad/Tile"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/RealDiv_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Sum_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape_1"
  input: "^gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
  input: "^gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
  input: "^gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_2"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
  input: "^gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_3"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
  input: "^gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_4"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/truediv_grad/tuple/control_dependency"
  input: "^gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/truediv_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Shape_1"
  op: "Shape"
  input: "weight0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Shape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency"
  input: "weight0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/mul_1"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/mul_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Sum_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape_1"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Shape_1"
  op: "Shape"
  input: "weight1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Shape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_1"
  input: "weight1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/mul_1"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/mul_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Sum_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape_1"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Shape_1"
  op: "Shape"
  input: "weight2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Shape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_2"
  input: "weight2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/mul_1"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/mul_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Sum_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape_1"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Shape_1"
  op: "Shape"
  input: "weight3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Shape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_3"
  input: "weight3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/mul_1"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/mul_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Sum_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape_1"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Shape"
  op: "Shape"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Shape_1"
  op: "Shape"
  input: "weight4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Shape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_4"
  input: "weight4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Sum"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/mul_1"
  op: "Mul"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits"
  input: "gradients/sequence_loss/sequence_loss_by_example/AddN_grad/tuple/control_dependency_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Sum_1"
  op: "Sum"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/mul_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Sum_1"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape_1"
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape_1"
  input: "^gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/zeros_like"
  op: "ZerosLike"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  op: "PreventGradient"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "message"
    value {
      s: "Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_grad/tuple/control_dependency"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/zeros_like_1"
  op: "ZerosLike"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  op: "PreventGradient"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "message"
    value {
      s: "Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_1_grad/tuple/control_dependency"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/zeros_like_2"
  op: "ZerosLike"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  op: "PreventGradient"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "message"
    value {
      s: "Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_2_grad/tuple/control_dependency"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/zeros_like_3"
  op: "ZerosLike"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  op: "PreventGradient"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "message"
    value {
      s: "Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_3_grad/tuple/control_dependency"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/zeros_like_4"
  op: "ZerosLike"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  op: "PreventGradient"
  input: "sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "message"
    value {
      s: "Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\'s interaction with tf.gradients()"
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: -1
      }
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/mul_4_grad/tuple/control_dependency"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  op: "Mul"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/sequence_loss/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits_grad/mul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/BiasAdd_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Const"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/Const"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/Const"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/Const"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/Const"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_1"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/MatMul_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_4/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_2"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_4_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_3"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1_grad/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Softmax_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Sum_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/Reshape_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_4"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_4_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/mul"
  op: "Mul"
  input: "gradients/AddN_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9"
  input: "gradients/AddN_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_5"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_9_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_9_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_12_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_13_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_8_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_8_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_14_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_12"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_4_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Size"
  op: "Size"
  input: "decoder4"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Reshape_1"
  op: "Reshape"
  input: "decoder4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_6"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_8_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_3/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_6"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1_grad/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Softmax_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Sum_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/Reshape_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_7"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_3_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/mul"
  op: "Mul"
  input: "gradients/AddN_7"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7"
  input: "gradients/AddN_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_8"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_7_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_7_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_8"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_8"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_9_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_10_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_6_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_6_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_11_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_9"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_3_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Size"
  op: "Size"
  input: "decoder3"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Reshape_1"
  op: "Reshape"
  input: "decoder3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_9"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_6_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_2/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_9"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1_grad/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Softmax_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Sum_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/Reshape_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_10"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_2_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/mul"
  op: "Mul"
  input: "gradients/AddN_10"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5"
  input: "gradients/AddN_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_11"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_5_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_5_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_11"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_11"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_6_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_7_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_4_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_8_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_6"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_2_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Size"
  op: "Size"
  input: "decoder2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Reshape_1"
  op: "Reshape"
  input: "decoder2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_12"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_4_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection_1/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_12"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1_grad/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Softmax_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Sum_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/Reshape_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_13"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_1_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/mul"
  op: "Mul"
  input: "gradients/AddN_13"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3"
  input: "gradients/AddN_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_14"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_3_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_14"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_14"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_3_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_4_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_2_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_5_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const_3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_1_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Size"
  op: "Size"
  input: "decoder1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Reshape_1"
  op: "Reshape"
  input: "decoder1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_15"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_2_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_15"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_1_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1_grad/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Sum/reduction_indices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Sum/reduction_indices"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Reshape/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\377\377\377\377\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Reshape/shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/sub"
  op: "Sub"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/mul_1"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/sub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Size"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/add"
  op: "Add"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum/reduction_indices"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/mod"
  op: "FloorMod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/add"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Size"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape_1"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/range/start"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/range/delta"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/range"
  op: "Range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/range/start"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/range/delta"
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Fill/value"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Fill"
  op: "Fill"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "index_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/range"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Maximum/y"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Maximum"
  op: "Maximum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/DynamicStitch"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Maximum/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/floordiv"
  op: "FloorDiv"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Maximum"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Shape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Softmax_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Tile"
  op: "Tile"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tmultiples"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 8
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Tile"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/read"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Sum_grad/Tile"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_16"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/control_dependency"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_17"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/add_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/add_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/add_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/control_dependency"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/read"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\001\000\000\000\001\000\000\000\010\000\000\000\010\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropInput"
  op: "Conv2DBackpropInput"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/read"
  input: "gradients/AddN_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropFilter"
  op: "Conv2DBackpropFilter"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Const"
  input: "gradients/AddN_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
  attr {
    key: "dilations"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "padding"
    value {
      s: "SAME"
    }
  }
  attr {
    key: "strides"
    value {
      list {
        i: 1
        i: 1
        i: 1
        i: 1
      }
    }
  }
  attr {
    key: "use_cudnn_on_gpu"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropInput"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropFilter"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropInput"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropInput"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropFilter"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/Conv2DBackpropFilter"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/add_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_18"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/mul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/mul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/mul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/mul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/control_dependency"
  attr {
    key: "N"
    value {
      i: 6
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/AddN_18"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Reshape_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 3
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/concat/axis"
  input: "gradients/embedding_attention_seq2seq/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/Reshape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/Reshape"
  input: "embedding_attention_seq2seq/Reshape_1"
  input: "embedding_attention_seq2seq/Reshape_2"
  input: "embedding_attention_seq2seq/Reshape_3"
  input: "embedding_attention_seq2seq/Reshape_4"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:1"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:2"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:3"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:4"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Slice_2"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ConcatOffset:2"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Slice_3"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ConcatOffset:3"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:3"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/Slice_4"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Reshape_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ConcatOffset:4"
  input: "gradients/embedding_attention_seq2seq/concat_grad/ShapeN:4"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/Slice_2"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/Slice_3"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/Slice_4"
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_2"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/concat_grad/Slice_2"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/concat_grad/Slice_2"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_3"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/concat_grad/Slice_3"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/concat_grad/Slice_3"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_4"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/concat_grad/Slice_4"
  input: "^gradients/embedding_attention_seq2seq/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/concat_grad/Slice_4"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_19"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/BiasAdd_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/BiasAdd_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/Reshape_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/Reshape_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_2"
  input: "gradients/embedding_attention_seq2seq/Reshape_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_3"
  input: "gradients/embedding_attention_seq2seq/Reshape_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/Reshape_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/concat_grad/tuple/control_dependency_4"
  input: "gradients/embedding_attention_seq2seq/Reshape_4_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_20"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_3/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_2/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_1/MatMul_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/MatMul_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0_4/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_21"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/mul"
  op: "Mul"
  input: "gradients/AddN_21"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1"
  input: "gradients/AddN_21"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_22"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_1_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 3
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_22"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_22"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_1_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Add_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Sigmoid_2_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Const"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/split_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_23"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat/axis"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_24"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/AddN_25"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/Reshape_4_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/Reshape_4_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/mul"
  op: "Mul"
  input: "gradients/AddN_25"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9"
  input: "gradients/AddN_25"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_26"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_14_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Const"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_27"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_28"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_9_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/attention_decoder_1/output_projection_wrapper/basic_lstm_cell/Mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_28"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_28"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros_grad/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\000\000\000\000\001\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/zeros_grad/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_9_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_13_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_12_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_13_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_8_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_8_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_14_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_12"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Shape"
  op: "Const"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Shape"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Size"
  op: "Size"
  input: "decoder0"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Size"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/concat_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Reshape_1"
  op: "Reshape"
  input: "decoder0"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_4_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Reshape"
  input: "gradients/concat/axis"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/concat_1/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/concat_1"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_4_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_3_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_2_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_1_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/embedding_lookup_grad/Reshape_1"
  input: "gradients/concat_1/axis"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4/axis"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/mod"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Shape"
  device: "/device:CPU:0"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Size"
  op: "Size"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_4"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Size"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_4"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_29"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/Reshape_3_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_4_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/Reshape_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/mul"
  op: "Mul"
  input: "gradients/AddN_29"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7"
  input: "gradients/AddN_29"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_11_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_30"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_7_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_12_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_30"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_30"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_7_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_10_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_9_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_10_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_6_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_6_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_11_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_9"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_3_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3/axis"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/mod"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Shape"
  device: "/device:CPU:0"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Size"
  op: "Size"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_3"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Size"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_3"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_31"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/Reshape_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_3_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/Reshape_2_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/mul"
  op: "Mul"
  input: "gradients/AddN_31"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5"
  input: "gradients/AddN_31"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_8_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_32"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_5_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_9_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_5_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_7_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_6_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_7_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_4_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_4_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_8_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_6"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_2_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2/axis"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/mod"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Shape"
  device: "/device:CPU:0"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Size"
  op: "Size"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Size"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_33"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/Reshape_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_2_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/Reshape_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/mul"
  op: "Mul"
  input: "gradients/AddN_33"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3"
  input: "gradients/AddN_33"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_5_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_34"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_3_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_6_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_34"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_34"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_3_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_4_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_3_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_4_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_2_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_2_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_5_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const_3"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_1_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1/axis"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/mod"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Shape"
  device: "/device:CPU:0"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Size"
  op: "Size"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Size"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/AddN_35"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/Reshape_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_1_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/Reshape_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/mul"
  op: "Mul"
  input: "gradients/AddN_35"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1"
  input: "gradients/AddN_35"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_2_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN_36"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_1_grad/TanhGrad"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_3_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Sum"
  op: "Sum"
  input: "gradients/AddN_36"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN_36"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Shape_1"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/mul"
  op: "Mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/mul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/mul_1"
  op: "Mul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_1_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/mul_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1_grad/SigmoidGrad"
  op: "SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_grad/TanhGrad"
  op: "TanhGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Mul_1_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split:2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Shape_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
          }
        }
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Shape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Sum"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Sum_1"
  op: "Sum"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Sum_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/Reshape_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_1_grad/SigmoidGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Tanh_grad/TanhGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Add_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Sigmoid_2_grad/SigmoidGrad"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/Const"
  attr {
    key: "N"
    value {
      i: 4
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
  op: "BiasAddGrad"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "data_format"
    value {
      s: "NHWC"
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_grad/concat"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/split_grad/concat"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_37"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/BiasAdd_4_grad/BiasAddGrad"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Rank"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/mod"
  op: "FloorMod"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat/axis"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Rank"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Shape"
  op: "Shape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ShapeN"
  op: "ShapeN"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup"
  input: "embedding_attention_seq2seq/rnn/EmbeddingWrapperZeroState/BasicLSTMCellZeroState/zeros_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ConcatOffset"
  op: "ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/mod"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ShapeN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ShapeN:1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ConcatOffset"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ShapeN"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice_1"
  op: "Slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ConcatOffset:1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/ShapeN:1"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/tuple/group_deps"
  op: "NoOp"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice_1"
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency_1"
  op: "Identity"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice_1"
  input: "^gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/tuple/group_deps"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/Slice_1"
      }
    }
  }
}
node {
  name: "gradients/AddN_38"
  op: "AddN"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_3_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_2_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_1_grad/tuple/control_dependency_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_grad/tuple/control_dependency_1"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/MatMul_4_grad/MatMul_1"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Shape"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT64
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "Z\000\000\000\000\000\000\000\010\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ToInt32"
  op: "Cast"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Shape"
  device: "/device:CPU:0"
  attr {
    key: "DstT"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT64
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/read"
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Size"
  op: "Size"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "out_type"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ExpandDims/dim"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ExpandDims"
  op: "ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Size"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ExpandDims/dim"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tdim"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice/stack"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice/stack_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice/stack_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice"
  op: "StridedSlice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ToInt32"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice/stack"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice/stack_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice/stack_2"
  attr {
    key: "Index"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "begin_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "ellipsis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "end_mask"
    value {
      i: 1
    }
  }
  attr {
    key: "new_axis_mask"
    value {
      i: 0
    }
  }
  attr {
    key: "shrink_axis_mask"
    value {
      i: 0
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/concat/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/concat"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ExpandDims"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/strided_slice"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/concat/axis"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Reshape"
  op: "Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/basic_lstm_cell/concat_grad/tuple/control_dependency"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/concat"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Reshape_1"
  op: "Reshape"
  input: "embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/ExpandDims"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tshape"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/concat_2/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/concat_2"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Reshape"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Reshape"
  input: "gradients/concat_2/axis"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/concat_3/axis"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/concat_3"
  op: "ConcatV2"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_4_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_3_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_2_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_1_grad/Reshape_1"
  input: "gradients/embedding_attention_seq2seq/rnn/rnn/embedding_wrapper/embedding_lookup_grad/Reshape_1"
  input: "gradients/concat_3/axis"
  attr {
    key: "N"
    value {
      i: 5
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "Tidx"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/mul"
  op: "Mul"
  input: "gradients/concat_2"
  input: "Variable/read"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/ScatterSub"
  op: "ScatterSub"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
  input: "gradients/concat_3"
  input: "GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/mul"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
  input: "Variable/read"
  input: "gradients/AddN_38"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
  input: "Variable/read"
  input: "gradients/AddN_37"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/embedding/mul"
  op: "Mul"
  input: "gradients/concat"
  input: "Variable/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/embedding/ScatterSub"
  op: "ScatterSub"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
  input: "gradients/concat_1"
  input: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/embedding/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "Tindices"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
  input: "Variable/read"
  input: "gradients/embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Conv2D_grad/tuple/control_dependency_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
  input: "Variable/read"
  input: "gradients/AddN_16"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
  input: "Variable/read"
  input: "gradients/AddN_27"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
  input: "Variable/read"
  input: "gradients/AddN_26"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
  input: "Variable/read"
  input: "gradients/AddN_24"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
  input: "Variable/read"
  input: "gradients/AddN_23"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
  input: "Variable/read"
  input: "gradients/AddN_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
  input: "Variable/read"
  input: "gradients/AddN_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
  input: "Variable/read"
  input: "gradients/AddN_20"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
  input: "Variable/read"
  input: "gradients/AddN_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
  input: "Variable/read"
  input: "gradients/AddN_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/ApplyGradientDescent"
  op: "ApplyGradientDescent"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
  input: "Variable/read"
  input: "gradients/AddN"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "GradientDescent/NoOp"
  op: "NoOp"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/embedding/ScatterSub"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/ApplyGradientDescent"
}
node {
  name: "GradientDescent/NoOp_1"
  op: "NoOp"
  input: "^GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/ScatterSub"
  input: "^GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/ApplyGradientDescent"
  input: "^GradientDescent/update_embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/ApplyGradientDescent"
  device: "/device:CPU:0"
}
node {
  name: "GradientDescent"
  op: "NoOp"
  input: "^GradientDescent/NoOp"
  input: "^GradientDescent/NoOp_1"
}
node {
  name: "save/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "model"
      }
    }
  }
}
node {
  name: "save/SaveV2/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 17
          }
        }
        string_val: "Variable"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
        string_val: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
        string_val: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
        string_val: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
}
node {
  name: "save/SaveV2/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 17
          }
        }
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
      }
    }
  }
}
node {
  name: "save/SaveV2"
  op: "SaveV2"
  input: "save/Const"
  input: "save/SaveV2/tensor_names"
  input: "save/SaveV2/shape_and_slices"
  input: "Variable"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/control_dependency"
  op: "Identity"
  input: "save/Const"
  input: "^save/SaveV2"
  attr {
    key: "T"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@save/Const"
      }
    }
  }
}
node {
  name: "save/RestoreV2/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "Variable"
      }
    }
  }
}
node {
  name: "save/RestoreV2/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2/tensor_names"
  input: "save/RestoreV2/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_1/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
}
node {
  name: "save/RestoreV2_1/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_1"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_1/tensor_names"
  input: "save/RestoreV2_1/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_2/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
}
node {
  name: "save/RestoreV2_2/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_2"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_2/tensor_names"
  input: "save/RestoreV2_2/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_3/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
}
node {
  name: "save/RestoreV2_3/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_3"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_3/tensor_names"
  input: "save/RestoreV2_3/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_4/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
}
node {
  name: "save/RestoreV2_4/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_4"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_4/tensor_names"
  input: "save/RestoreV2_4/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_5/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
}
node {
  name: "save/RestoreV2_5/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_5"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_5/tensor_names"
  input: "save/RestoreV2_5/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_6/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
}
node {
  name: "save/RestoreV2_6/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_6"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_6/tensor_names"
  input: "save/RestoreV2_6/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_7/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
}
node {
  name: "save/RestoreV2_7/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_7"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_7/tensor_names"
  input: "save/RestoreV2_7/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_8/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
}
node {
  name: "save/RestoreV2_8/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_8"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_8/tensor_names"
  input: "save/RestoreV2_8/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_9/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
}
node {
  name: "save/RestoreV2_9/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_9"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_9/tensor_names"
  input: "save/RestoreV2_9/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_10/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "save/RestoreV2_10/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_10"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_10/tensor_names"
  input: "save/RestoreV2_10/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_11/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
}
node {
  name: "save/RestoreV2_11/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_11"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_11/tensor_names"
  input: "save/RestoreV2_11/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_12/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
}
node {
  name: "save/RestoreV2_12/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_12"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_12/tensor_names"
  input: "save/RestoreV2_12/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_13/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
}
node {
  name: "save/RestoreV2_13/shape_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_13"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_13/tensor_names"
  input: "save/RestoreV2_13/shape_and_slices"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_14/tensor_names"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
}
node {
  name: "save/RestoreV2_14/shape_and_slices"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_14"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_14/tensor_names"
  input: "save/RestoreV2_14/shape_and_slices"
  device: "/device:CPU:0"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_15/tensor_names"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
}
node {
  name: "save/RestoreV2_15/shape_and_slices"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_15"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_15/tensor_names"
  input: "save/RestoreV2_15/shape_and_slices"
  device: "/device:CPU:0"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/RestoreV2_16/tensor_names"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
}
node {
  name: "save/RestoreV2_16/shape_and_slices"
  op: "Const"
  device: "/device:CPU:0"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 1
          }
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/RestoreV2_16"
  op: "RestoreV2"
  input: "save/Const"
  input: "save/RestoreV2_16/tensor_names"
  input: "save/RestoreV2_16/shape_and_slices"
  device: "/device:CPU:0"
  attr {
    key: "dtypes"
    value {
      list {
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/Assign"
  op: "Assign"
  input: "Variable"
  input: "save/RestoreV2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@Variable"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_1"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
  input: "save/RestoreV2_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_2"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
  input: "save/RestoreV2_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_3"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
  input: "save/RestoreV2_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_4"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
  input: "save/RestoreV2_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_5"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
  input: "save/RestoreV2_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_6"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
  input: "save/RestoreV2_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_7"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
  input: "save/RestoreV2_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_8"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
  input: "save/RestoreV2_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_9"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
  input: "save/RestoreV2_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_10"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
  input: "save/RestoreV2_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_11"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
  input: "save/RestoreV2_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_12"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
  input: "save/RestoreV2_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_13"
  op: "Assign"
  input: "embedding_attention_seq2seq/embedding_attention_decoder/embedding"
  input: "save/RestoreV2_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/embedding_attention_decoder/embedding"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_14"
  op: "Assign"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
  input: "save/RestoreV2_14"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_15"
  op: "Assign"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
  input: "save/RestoreV2_15"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/Assign_16"
  op: "Assign"
  input: "embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
  input: "save/RestoreV2_16"
  device: "/device:CPU:0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "_class"
    value {
      list {
        s: "loc:@embedding_attention_seq2seq/rnn/embedding_wrapper/embedding"
      }
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_all/NoOp"
  op: "NoOp"
  input: "^save/Assign"
  input: "^save/Assign_1"
  input: "^save/Assign_2"
  input: "^save/Assign_3"
  input: "^save/Assign_4"
  input: "^save/Assign_5"
  input: "^save/Assign_6"
  input: "^save/Assign_7"
  input: "^save/Assign_8"
  input: "^save/Assign_9"
  input: "^save/Assign_10"
  input: "^save/Assign_11"
  input: "^save/Assign_12"
  input: "^save/Assign_13"
}
node {
  name: "save/restore_all/NoOp_1"
  op: "NoOp"
  input: "^save/Assign_14"
  input: "^save/Assign_15"
  input: "^save/Assign_16"
  device: "/device:CPU:0"
}
node {
  name: "save/restore_all"
  op: "NoOp"
  input: "^save/restore_all/NoOp"
  input: "^save/restore_all/NoOp_1"
}
node {
  name: "init/NoOp"
  op: "NoOp"
  input: "^Variable/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/embedding/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/kernel/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/bias/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/kernel/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/basic_lstm_cell/bias/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/kernel/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/output_projection_wrapper/bias/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/kernel/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/bias/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/kernel/Assign"
  input: "^embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/bias/Assign"
}
node {
  name: "init/NoOp_1"
  op: "NoOp"
  input: "^embedding_attention_seq2seq/rnn/embedding_wrapper/embedding/Assign"
  input: "^embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/kernel/Assign"
  input: "^embedding_attention_seq2seq/rnn/embedding_wrapper/basic_lstm_cell/bias/Assign"
  device: "/device:CPU:0"
}
node {
  name: "init"
  op: "NoOp"
  input: "^init/NoOp"
  input: "^init/NoOp_1"
}
versions {
  producer: 25
}
